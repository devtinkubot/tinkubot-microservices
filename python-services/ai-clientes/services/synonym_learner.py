"""
Synonym Learner Service - Aprendizaje Autom√°tico de Sin√≥nimos.

Este m√≥dulo implementa aprendizaje autom√°tico de sin√≥nimos a partir de b√∫squedas
exitosas. Los sin√≥nimos aprendidos se agregan AUTOM√ÅTICAMENTE a service_synonyms.

ESTRATEGIA AUTOM√ÅTICA:
- Feature flag: USE_SYNONYM_LEARNING (default: False)
- Agrega autom√°ticamente a service_synonyms
- NO requiere aprobaci√≥n manual
- Mantener tracking en learned_synonyms para auditor√≠a

L√ìGICA DE APRENDIZAJE:
1. Una b√∫squeda encuentra resultados (num_results > 0)
2. El query NO existe en service_synonyms
3. El query es diferente a la profesi√≥n can√≥nica
4. Se calcula confidence_score
5. Se inserta AUTOM√ÅTICAMENTE en service_synonyms (status='approved')
6. Se mantiene registro en learned_synonyms para auditor√≠a

Author: Claude Sonnet 4.5
Created: 2026-01-15
Updated: 2026-01-15 - Automatizado (sin aprobaci√≥n manual)
"""

import logging
from typing import Any, Dict, Optional
from decimal import Decimal

from utils.db_utils import run_supabase

logger = logging.getLogger(__name__)


class SynonymLearner:
    """
    Sistema de aprendizaje autom√°tico de sin√≥nimos.

    Responsabilidades:
    - Observar b√∫squedas exitosas
    - Extraer potenciales nuevos sin√≥nimos
    - Calcular confidence score
    - Insertar AUTOM√ÅTICAMENTE en service_synonyms
    - Mantener registro en learned_synonyms para auditor√≠a

    AUTOM√ÅTICO: No requiere aprobaci√≥n manual.
    """

    def __init__(self, supabase_client):
        """Inicializa el sistema de aprendizaje.

        Args:
            supabase_client: Cliente Supabase para guardar aprendizajes
        """
        self.supabase = supabase_client
        logger.info("‚úÖ SynonymLearner inicializado")

    async def learn_from_search(
        self,
        query: str,
        matched_profession: str,
        num_results: int,
        city: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Aprende un sin√≥nimo potencial de una b√∫squeda exitosa.

        Args:
            query: Query original del usuario
            matched_profession: Profesi√≥n que hizo match
            num_results: N√∫mero de resultados encontrados
            city: Ciudad de b√∫squeda (opcional)
            context: Contexto adicional (expansion_method, etc.)

        Returns:
            Dict con el aprendizaje creado o None si no se aprendi√≥ nada

        Example:
            >>> learner = SynonymLearner(supabase)
            >>> result = await learner.learn_from_search(
            ...     query="community manager",
            ...     matched_profession="marketing",
            ...     num_results=5
            ... )
        """
        from core.feature_flags import USE_SYNONYM_LEARNING

        # Feature flag: desactivado = no aprender
        if not USE_SYNONYM_LEARNING:
            logger.debug("‚ö†Ô∏è USE_SYNONYM_LEARNING=False, skipping learning")
            return None

        # Validaciones previas
        if not self._should_learn(query, matched_profession, num_results):
            logger.debug(f"Query '{query}' no cumple criterios de aprendizaje")
            return None

        try:
            # Normalizar query
            normalized_query = self._normalize_query(query)
            if not normalized_query:
                return None

            # Verificar si ya existe en learned_synonyms
            existing = await self._get_existing_learned(
                matched_profession,
                normalized_query
            )

            if existing:
                # Actualizar match_count y confidence
                return await self._update_existing_learned(existing)

            # Calcular confidence score inicial
            confidence = self._calculate_confidence_score(
                query=query,
                matched_profession=matched_profession,
                num_results=num_results,
                context=context
            )

            # Insertar AUTOM√ÅTICAMENTE en service_synonyms
            # Primero verificar si ya existe en service_synonyms
            existing_in_service = await self._check_existing_in_service_synonyms(
                matched_profession,
                normalized_query
            )

            if existing_in_service:
                # Ya existe, solo actualizar match_count en learned_synonyms
                logger.debug(f"Sin√≥nimo '{normalized_query}' ya existe en service_synonyms")
                return None

            # Insertar en service_synonyms AUTOM√ÅTICAMENTE
            inserted = await self._insert_to_service_synonyms(
                canonical_profession=matched_profession,
                synonym=normalized_query
            )

            if inserted:
                # Guardar registro en learned_synonyms para auditor√≠a (status='approved')
                learned = await self._insert_learned_synonym_audit(
                    canonical_profession=matched_profession,
                    learned_synonym=normalized_query,
                    source_query=query,
                    confidence_score=confidence
                )

                # Refrescar cache de service_synonyms
                from services.dynamic_service_catalog import dynamic_service_catalog
                if dynamic_service_catalog:
                    await dynamic_service_catalog.refresh_cache()

                logger.info(
                    f"üß† [LEARNING] Nuevo sin√≥nimo aprendido AUTOM√ÅTICAMENTE: '{normalized_query}' ‚Üí '{matched_profession}' "
                    f"(confidence: {confidence:.2f}, results: {num_results})"
                )

                return learned

            return None

        except Exception as e:
            logger.error(f"‚ùå Error en learn_from_search: {e}")
            return None

    def _should_learn(
        self,
        query: str,
        matched_profession: str,
        num_results: int
    ) -> bool:
        """
        Determina si una b√∫squeda cumple criterios para aprendizaje.

        Criterios:
        1. Debe tener al menos 1 resultado
        2. El query debe ser diferente a la profesi√≥n can√≥nica
        3. El query no debe ser un n√∫mero puro
        4. El query debe tener longitud m√≠nima (3 caracteres)
        """
        # Criterio 1: Debe tener resultados
        if num_results == 0:
            logger.debug(f"No learning: sin resultados")
            return False

        # Criterio 2: Query diferente a profesi√≥n can√≥nica
        if query.lower().strip() == matched_profession.lower().strip():
            logger.debug(f"No learning: query igual a profesi√≥n can√≥nica")
            return False

        # Criterio 3: No ser un n√∫mero puro
        if query.strip().isdigit():
            logger.debug(f"No learning: query es n√∫mero puro")
            return False

        # Criterio 4: Longitud m√≠nima
        if len(query.strip()) < 3:
            logger.debug(f"No learning: query muy corto")
            return False

        # Criterio 5: Query no debe contener solo stopwords
        if self._is_stopword_only(query):
            logger.debug(f"No learning: query solo contiene stopwords")
            return False

        return True

    def _normalize_query(self, query: str) -> Optional[str]:
        """Normaliza el query para almacenamiento."""
        if not query:
            return None

        # Min√∫sculas, trim, sin espacios extras
        normalized = query.lower().strip()

        # Limitar longitud m√°xima (200 caracteres como en la DB)
        if len(normalized) > 200:
            normalized = normalized[:200]

        return normalized

    def _is_stopword_only(self, query: str) -> bool:
        """Verifica si el query solo contiene palabras vac√≠as."""
        stopwords = {
            'el', 'la', 'de', 'en', 'un', 'una', 'por', 'para',
            'con', 'sin', 'sobre', 'tras', 'hasta', 'desde',
            'que', 'qual', 'como', 'donde', 'cuando', 'quien'
        }

        query_lower = query.lower().strip()
        words = query_lower.split()

        # Si todas las palabras son stopwords
        return all(word in stopwords for word in words)

    async def _get_existing_learned(
        self,
        canonical_profession: str,
        learned_synonym: str
    ) -> Optional[Dict[str, Any]]:
        """Busca si ya existe un aprendizaje previo."""
        try:
            result = await run_supabase(
                lambda: self.supabase.table("learned_synonyms")
                .select("*")
                .eq("canonical_profession", canonical_profession)
                .eq("learned_synonym", learned_synonym)
                .execute(),
                label="synonym_learner.get_existing"
            )

            if result.data:
                return result.data[0]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error buscando aprendizaje existente: {e}")

        return None

    async def _update_existing_learned(
        self,
        existing: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Actualiza un aprendizaje existente incrementando match_count."""
        try:
            new_match_count = existing.get("match_count", 1) + 1
            new_confidence = self._recalculate_confidence(existing, new_match_count)

            updated = await run_supabase(
                lambda: self.supabase.table("learned_synonyms")
                .update({
                    "match_count": new_match_count,
                    "confidence_score": new_confidence,
                    "last_seen_at": "NOW()"
                })
                .eq("id", existing["id"])
                .execute(),
                label="synonym_learner.update_existing"
            )

            if updated.data:
                logger.info(
                    f"üîÑ [LEARNING] Aprendizaje actualizado: '{existing['learned_synonym']}' "
                    f"(match_count: {new_match_count}, confidence: {new_confidence:.2f})"
                )
                return updated.data[0]

        except Exception as e:
            logger.error(f"‚ùå Error actualizando aprendizaje: {e}")

        return existing

    def _calculate_confidence_score(
        self,
        query: str,
        matched_profession: str,
        num_results: int,
        context: Optional[Dict[str, Any]] = None
    ) -> Decimal:
        """
        Calcula el confidence score inicial (0.00 a 1.00).

        Factores:
        1. N√∫mero de resultados (m√°s resultados = m√°s confianza)
        2. Longitud del query (no muy corto, no muy largo)
        3. Exactitud del match (si contiene parte de la profesi√≥n)
        4. M√©todo de expansi√≥n usado (AI > dynamic > static)
        """
        confidence = Decimal("0.50")  # Base confidence

        # Factor 1: N√∫mero de resultados
        if num_results >= 10:
            confidence += Decimal("0.20")
        elif num_results >= 5:
            confidence += Decimal("0.10")
        elif num_results >= 2:
            confidence += Decimal("0.05")

        # Factor 2: Longitud del query
        query_len = len(query.split())
        if 2 <= query_len <= 4:  # Ideal
            confidence += Decimal("0.10")
        elif query_len > 6:  # Muy largo
            confidence -= Decimal("0.10")

        # Factor 3: Exactitud del match
        query_lower = query.lower()
        profession_lower = matched_profession.lower()

        # Si el query contiene parte de la profesi√≥n
        if any(word in profession_lower for word in query_lower.split()):
            confidence += Decimal("0.15")

        # Factor 4: M√©todo de expansi√≥n
        expansion_method = context.get("expansion_method") if context else None
        if expansion_method == "ai":
            confidence += Decimal("0.10")
        elif expansion_method == "dynamic":
            confidence += Decimal("0.05")

        # Limitar rango [0.00, 1.00]
        confidence = max(Decimal("0.00"), min(Decimal("1.00"), confidence))

        return confidence

    def _recalculate_confidence(
        self,
        existing: Dict[str, Any],
        new_match_count: int
    ) -> Decimal:
        """Recalcula confidence basado en match_count acumulado."""
        current_confidence = Decimal(str(existing.get("confidence_score", 0.50)))

        # Cada match adicional incrementa confianza
        # pero con diminishing returns
        increment = Decimal("0.05") / (new_match_count ** 0.5)

        new_confidence = current_confidence + increment

        # Limitar a 1.00
        return min(Decimal("1.00"), new_confidence)

    async def _check_existing_in_service_synonyms(
        self,
        canonical_profession: str,
        synonym: str
    ) -> bool:
        """Verifica si ya existe en service_synonyms."""
        try:
            result = await run_supabase(
                lambda: self.supabase.table("service_synonyms")
                .select("*")
                .eq("canonical_profession", canonical_profession)
                .eq("synonym", synonym)
                .execute(),
                label="synonym_learner.check_existing_service"
            )

            return len(result.data) > 0

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error verificando service_synonyms: {e}")
            return False

    async def _insert_to_service_synonyms(
        self,
        canonical_profession: str,
        synonym: str
    ) -> bool:
        """Inserta autom√°ticamente en service_synonyms."""
        try:
            result = await run_supabase(
                lambda: self.supabase.table("service_synonyms")
                .insert({
                    "canonical_profession": canonical_profession,
                    "synonym": synonym,
                    "active": True
                })
                .execute(),
                label="synonym_learner.insert_to_service_synonyms"
            )

            return len(result.data) > 0

        except Exception as e:
            logger.error(f"‚ùå Error insertando en service_synonyms: {e}")
            return False

    async def _insert_learned_synonym_audit(
        self,
        canonical_profession: str,
        learned_synonym: str,
        source_query: str,
        confidence_score: Decimal
    ) -> Optional[Dict[str, Any]]:
        """Inserta registro de auditor√≠a en learned_synonyms (status='approved')."""
        try:
            result = await run_supabase(
                lambda: self.supabase.table("learned_synonyms")
                .insert({
                    "canonical_profession": canonical_profession,
                    "learned_synonym": learned_synonym,
                    "source_query": source_query,
                    "confidence_score": float(confidence_score),
                    "match_count": 1,
                    "status": "approved",
                    "approved_by": "system_auto",
                    "approved_at": "NOW()"
                })
                .execute(),
                label="synonym_learner.insert_audit"
            )

            if result.data:
                return result.data[0]

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error insertando auditor√≠a (no cr√≠tico): {e}")

        return None

    # ============================================================================
    # M√âTODOS DE AUDITOR√çA (SISTEMA AUTOM√ÅTICO)
    # ============================================================================

    async def get_learning_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas del sistema de aprendizaje autom√°tico."""
        try:
            # Total aprendidos (todos con status='approved')
            result = await run_supabase(
                lambda: self.supabase.table("learned_synonyms")
                .select("*")
                .eq("status", "approved")
                .execute(),
                label="synonym_learner.stats"
            )

            total_auto_learned = len(result.data) if result.data else 0

            # Top profesiones m√°s aprendidas
            top_result = await run_supabase(
                lambda: self.supabase.table("learned_synonyms")
                .select("canonical_profession")
                .eq("status", "approved")
                .execute(),
                label="synonym_learner.top_professions"
            )

            # Contar por profesi√≥n
            profession_counts = {}
            if top_result.data:
                for item in top_result.data:
                    prof = item.get("canonical_profession", "unknown")
                    profession_counts[prof] = profession_counts.get(prof, 0) + 1

            # Ordenar top 5
            top_professions = sorted(
                profession_counts.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]

            return {
                "total_auto_learned": total_auto_learned,
                "learning_method": "automatic",
                "top_professions": [
                    {"profession": prof, "count": count}
                    for prof, count in top_professions
                ]
            }

        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estad√≠sticas: {e}")
            return {}


# ============================================================================
# INSTANCIA GLOBAL (se inicializa en main.py)
# ============================================================================

synonym_learner: Optional[SynonymLearner] = None


def initialize_synonym_learner(supabase_client) -> None:
    """Inicializa el sistema de aprendizaje de sin√≥nimos.

    Args:
        supabase_client: Cliente Supabase
    """
    global synonym_learner

    if supabase_client:
        synonym_learner = SynonymLearner(supabase_client)
        logger.info("‚úÖ SynonymLearner inicializado")
    else:
        synonym_learner = None
        logger.warning("‚ö†Ô∏è SynonymLearner deshabilitado (sin Supabase)")
