# Search Service

Microservicio especializado en b√∫squeda ultra-r√°pida de proveedores para TinkuBot.

## üöÄ Caracter√≠sticas

- **B√∫squeda por tokens**: Ultra-r√°pida (< 50ms) usando √≠ndices optimizados
- **B√∫squeda full-text**: Para consultas complejas y descriptivas
- **B√∫squeda h√≠brida**: Combina m√∫ltiples estrategias
- **Mejora con IA**: OpenAI integrada para consultas ambiguas
- **Cach√© inteligente**: Redis para respuestas instant√°neas
- **Orquestaci√≥n autom√°tica**: Selecciona la mejor estrategia seg√∫n la consulta
- **Normalizaci√≥n avanzada**: Texto sin acentos, min√∫sculas, sin caracteres especiales

## üìã Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AI Clientes   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Search Service  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  PostgreSQL     ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ  (FastAPI)       ‚îÇ    ‚îÇ  + √çndices      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   Redis Cache   ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   OpenAI API    ‚îÇ
                       ‚îÇ  (opcional)     ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üèÉ‚Äç‚ôÇÔ∏è Inicio R√°pido

### 1. Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

### 2. con Docker (a trav√©s del proyecto principal)

El servicio search-token se ejecuta como parte del docker-compose principal del proyecto:

```bash
# Desde la ra√≠z del proyecto
docker-compose up -d search-token
```

### 3. Local

```bash
pip install -r requirements.txt
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

## üìö API Documentation

Una vez iniciado, visita:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## üîç Endpoints Principales

### Buscar Proveedores

```bash
POST /api/v1/search
Content-Type: application/json

{
  "query": "necesito m√©dico en Quito urgente",
  "filters": {
    "available_only": true,
    "min_rating": 4.0,
    "city": "Quito"
  },
  "limit": 10,
  "use_ai_enhancement": true
}
```

### Sugerencias de Autocompletado

```bash
GET /api/v1/suggestions?q=m√©dico&limit=5
```

### Analizar Consulta

```bash
GET /api/v1/analyze?q=necesito plomero en guayaquil
```

### Health Check

```bash
GET /api/v1/health
```

## üéØ Estrategias de B√∫squeda

### 1. Token-Based (por defecto)
- **Velocidad**: < 50ms
- **Ideal**: "m√©dico quito", "plomero", "abogado"
- **C√≥mo funciona**: Busca coincidencias exactas de tokens normalizados

### 2. Full-Text
- **Velocidad**: 100-200ms
- **Ideal**: "necesito alguien que arregle la tuber√≠a de la cocina"
- **C√≥mo funciona**: B√∫squeda sem√°ntica con PostgreSQL tsvector

### 3. Hybrid
- **Velocidad**: 100-300ms
- **Ideal**: Consultas con m√∫ltiples interpretaciones
- **C√≥mo funciona**: Combina resultados de ambas estrategias

### 4. AI-Enhanced
- **Velocidad**: 300-600ms
- **Ideal**: "ayuda con algo legal", "tengo un problema t√©cnico"
- **C√≥mo funciona**: OpenAI mejora la consulta antes de buscar

## üóÉÔ∏è Base de Datos Optimizada

### √çndices Especializados

```sql
-- B√∫squeda por contenci√≥n de arrays
CREATE INDEX idx_profession_tokens_gin
ON provider_search_index USING GIN(profession_tokens);

-- B√∫squeda full-text
CREATE INDEX idx_search_vector_gin
ON provider_search_index USING GIN(search_vector);

-- B√∫squedas compuestas
CREATE INDEX idx_city_active
ON provider_search_index(city_normalized, is_active);
```

### Funciones de B√∫squeda

```sql
-- B√∫squeda optimizada por tokens
SELECT * FROM search_providers_by_tokens(
    ARRAY['medico', 'doctor'],
    'Quito',
    10, 0
);
```

## üîÑ Integraci√≥n con AI Clientes

### Modo de uso

```python
import httpx

async def search_in_service(query: str):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://search-token:8000/api/v1/search",
            json={
                "query": query,
                "use_ai_enhancement": True,
                "limit": 5
            }
        )
        return response.json()
```

### Flujo de Decisi√≥n

1. **Consulta clara** ‚Üí Token-based (instant√°neo)
2. **Consulta ambigua** ‚Üí AI-enhanced (inteligente)
3. **Consulta compleja** ‚Üí Hybrid (completo)

## üìä M√©tricas y Monitoreo

### M√©tricas Disponibles

```bash
GET /api/v1/metrics
```

- B√∫squedas totales
- Cache hit ratio
- Uso de IA
- Tiempos de respuesta
- Consultas populares

### M√©tricas de Prometheus

```bash
# Disponible en :9091/metrics
curl http://localhost:9091/metrics
```

## üîß Configuraci√≥n

### Variables Clave

| Variable | Default | Descripci√≥n |
|----------|---------|-------------|
| `DATABASE_URL` | - | URL de PostgreSQL |
| `REDIS_URL` | `redis://localhost:6379/1` | URL de Redis |
| `OPENAI_API_KEY` | - | API Key de OpenAI (opcional) |
| `MAX_SEARCH_RESULTS` | `20` | M√°ximo de resultados |
| `CACHE_TTL_SECONDS` | `300` | TTL del cach√© |

### Performance Tuning

```python
# PostgreSQL settings (postgresql.conf)
shared_preload_libraries = 'pg_trgm'
random_page_cost = 1.1  # SSD
effective_cache_size = '4GB'
work_mem = '64MB'
```

## üß™ Testing

```bash
# Tests unitarios
python -m pytest tests/

# Tests de integraci√≥n
python -m pytest tests/integration/

# Tests de carga
python -m pytest tests/load/
```

## üöÄ Despliegue

### Producci√≥n

```bash
# Build
docker build -t tinkubot/search-token .

# Run
docker run -d \
  --name search-token \
  -p 8000:8000 \
  -e DATABASE_URL=$DATABASE_URL \
  -e REDIS_URL=$REDIS_URL \
  tinkubot/search-token
```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: search-token
spec:
  replicas: 3
  selector:
    matchLabels:
      app: search-token
  template:
    metadata:
      labels:
        app: search-token
    spec:
      containers:
      - name: search-token
        image: tinkubot/search-token:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: tinkubot-secrets
              key: database-url
```

## üîç Troubleshooting

### Problemas Comunes

**B√∫squedas lentas (> 500ms)**
```bash
# Verificar √≠ndices
psql -d tinkubot -c "\d+ provider_search_index"

# Rebuild √≠ndices
psql -d tinkubot -c "REINDEX INDEX provider_search_index_pkey;"
```

**Cache no funciona**
```bash
# Verificar Redis
curl http://localhost:8000/api/v1/cache/info

# Limpiar cach√©
curl -X DELETE http://localhost:8000/api/v1/cache/clear
```

**IA no mejora consultas**
```bash
# Verificar API Key
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

## üìà Mejoras Futuras

- [ ] B√∫squeda por geolocalizaci√≥n
- [ ] Aprendizaje autom√°tico de preferencias
- [ ] B√∫squeda por disponibilidad en tiempo real
- [ ] Integraci√≥n con m√°s APIs de IA
- [ ] Sistema de recomendaciones personalizado

## üìù Licencia

MIT License - ver archivo LICENSE